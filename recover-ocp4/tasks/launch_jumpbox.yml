---
- name: Install prereq package
  become: true
  hosts: localhost
  connection: local
  tasks:
    - name: version check
      assert:
        that: "ansible_version.full is version_compare('2.8', '>=')"
        msg: >
          "You must update Ansible to at least 2.8.  run 'sudo yum -y install ansible'"

    - name: get prereq python2-boto and python2-boto3 packages
      become: true
      yum:
        state: latest
        name: "{{ packages }}"
      vars:
        packages:
          - python2-boto 
          - python2-boto3

- name: Gather Info about AWS
  hosts: localhost
  connection: local
  gather_facts: false
  vars:
    cluster_key_filename: "{{ lookup('env', 'HOME') }}/.ssh/cluster-{{ lookup('env', 'GUID') }}-key.pub"
    GUID: "{{ lookup('env', 'GUID') }}"
    HOME: "{{ lookup('env', 'HOME') }}"
    ssh_config: "{{ lookup('env', 'HOME') }}/.ssh/config"

  tasks:


    - name: get control plane nodes
      ec2_instance_facts:
        filters:
          "tag:Name": "*master*"
      register: control_plane

    - name: add control_planes to inventory
      add_host: 
        name: "{{ item.private_dns_name }}"
        groups: control_plane
      loop: "{{ control_plane.instances }}"
      when: control_plane.instances[0] is defined

    - name: get cluster vpc ID
      set_fact:
        cluster_vpc: "{{ control_plane.instances[0].vpc_id }}"
        # chop off the last character
        cluster_region: "{{ control_plane.instances[0].placement.availability_zone| regex_replace('.$') }}"
      when: control_plane.instances[0] is defined


    - name: get workers
      ec2_instance_facts:
        filters:
          "tag:Name": "*worker*"
      register: workers

    - name: add workers to inventory
      add_host:
        name: "{{ item.private_dns_name }}"
        groups: workers
      loop: "{{ workers.instances }}"
      when: workers.instances[0] is defined

    - name: is there a jumpbox?
      ec2_instance_facts:
        filters:
          "tag:type": "jumpbox"
      register: jumpboxes

    - name: add existing jumpbox to inventory
      add_host:
        name: "{{ jumpboxes.instances[0].public_ip_address }}"
        groups: jumpbox
      when: jumpboxes.instances[0] is defined

    - name: setup jumpbox
      block:

      - name: Put the cluster keypair in AWS for jumphost
        ec2_key:
          name: cluster_keypair
          key_material: "{{ lookup('file', cluster_key_filename) }}"

      - name: Create SSH security group
        ec2_group:
          name: jumpbox
          description: jumpbox description
          region: "{{ cluster_region }}"
          vpc_id: "{{ cluster_vpc }}"
          rules:
            - proto: tcp
              ports: 22
              cidr_ip: 0.0.0.0/0
        register: sg_jumpbox

      - name: get vpc_subnet_id
        ec2_vpc_subnet_facts:
          filters:
            vpc-id: "{{ sg_jumpbox.vpc_id }}"
            cidr-block: "10.0.0.0/20"
        register: ec2_vpc_subnet_ids

      - name: debug me
        debug:
          var: ec2_vpc_subnet_ids
          verbosity: 4

      - name: launch ec2 instance
        ec2:
          key_name: "cluster_keypair"
          instance_type: t2.micro
          group_id: "{{ sg_jumpbox.group_id }}"
          image: ami-0520e698dd500b1d1
          wait: true
          region: "{{ cluster_region }}"
          vpc_subnet_id: "{{ ec2_vpc_subnet_ids.subnets[0].subnet_id }}"
          assign_public_ip: yes
          instance_tags:
            type: jumpbox
        register: ec2

      - name: Add jumpbox instance public IP to host group
        add_host:
          name: "{{ ec2.instances[0].public_ip }}"
          groups: jumpbox

      - name: Wait for SSH to come up
        delegate_to: "{{ ec2.instances[0].public_ip }}"
        wait_for_connection:
          delay: 10
          timeout: 180

      when: jumpboxes["instances"][0] is not defined

    - name: delete clientvm ssh config
      file:
        dest: "{{ ssh_config }}"
        state: absent

    - name: create empty ssh config
      file:
        dest: "{{ ssh_config }}"
        state: touch
        mode: 0600

    - name: setup clientvm ssh config
      blockinfile:
        dest: "{{ ssh_config }}"
        marker: "##### {mark} Adding masters with ProxyJump"
        content: |
          Host {{ jumpboxes.instances[0].public_ip_address }}
            User ec2-user
            StrictHostKeyChecking no

          Host *.internal
            User core
            ProxyJump {{ jumpboxes.instances[0].public_ip_address }}
            StrictHostKeyChecking no

          Match User ec2-user
            IdentityFile ~/.ssh/cluster-{{ GUID }}-key

          Match User core
            IdentityFile ~/.ssh/cluster-{{ GUID }}-key

          Host *
            ControlMaster auto
            ControlPath /tmp/%h-%r
            ControlPersist 5m
            StrictHostKeyChecking no

- name: prep jumpbox
  hosts: jumpbox
  vars:
    GUID: "{{ lookup('env', 'GUID') }}"
    HOME: "{{ lookup('env', 'HOME') }}"
    ssh_config: "{{ ansible_env.HOME }}/.ssh/config"
  tasks:

  - name: put kubeconfig on jumpbox
    copy:
      src: "{{ HOME }}/cluster-{{ GUID }}/auth/kubeconfig"
      dest: "{{ ansible_env.HOME }}/kubeconfig"

  - name: copy cluster ssh key to jumpbox
    copy:
      src: "{{ HOME }}/.ssh/cluster-{{ GUID }}-key"
      dest: "{{ ansible_env.HOME }}/.ssh/"
      mode: 0600

  - name: delete jumpbox ssh config
    file:
      dest: "{{ ssh_config }}"
      state: absent

  - name: create empty ssh config
    file:
      dest: "{{ ssh_config }}"
      state: touch
      mode: 0600

  - name: setup ssh config on jumpbox
    blockinfile:
      dest: "{{ ssh_config }}"
      marker: "##### {mark} ADD default key and user"
      content: |
        Host *
          IdentityFile {{ ansible_env.HOME }}/.ssh/cluster-{{ GUID }}-key
          User core
          StrictHostKeyChecking no
          ControlPath /tmp/{{ GUID }}-%r-%h-%p
          ControlPersist 5m

